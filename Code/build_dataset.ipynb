{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stake .csv to DDF and Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stake Class Auto Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from stake_class import Stake\n",
    "import math\n",
    "import tkinter as tk\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stake Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stake_dataset(stake_folder):\n",
    "    global directory\n",
    "    directory='/Users/cmarkovsky/Desktop/AK_REU/NEW_STAKES/Data/' #INSERT YOUR FILE DIRECTORY HERE\n",
    "    stake_files=os.listdir(directory+stake_folder)\n",
    "    coords_dict = {}\n",
    "    stake_dict = {}\n",
    "    melt_dict = {}\n",
    "    DDF_dict = {}\n",
    "    for file in stake_files:\n",
    "        stake_name = file.replace('.csv','')\n",
    "        cur_stake = Stake(directory, stake_folder, file)\n",
    "        dates = cur_stake.df['date']\n",
    "        surface_type = cur_stake.df['surface_type']\n",
    "        if (not (dates.size < 2)) & ('Debris' in surface_type.values):\n",
    "            cur_melt = cur_stake.get_melt()\n",
    "            cur_ddf = determine_DDF(cur_melt)\n",
    "            stake_dict[stake_name] = cur_stake\n",
    "            melt_dict[stake_name] = cur_melt\n",
    "            DDF_dict[stake_name] = cur_ddf\n",
    "            coords_dict[stake_name] = cur_stake.coords\n",
    "            \n",
    "    full_dict = {'stake_info':stake_dict, 'melt_info':melt_dict, 'DDF_info':DDF_dict, 'coords_info':coords_dict}\n",
    "    \n",
    "    return full_dict\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = build_stake_dataset('Kennicott Stake Records-V4_NEW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_AWS_dataset(AWS_file):\n",
    "    ### Builds a dataset for the AWS data\n",
    "    \n",
    "    AWS_folder = 'AWS_data'\n",
    "    try:  \n",
    "        AWS_file=pd.read_csv(directory+AWS_folder+'/'+AWS_file)\n",
    "    except IOError:\n",
    "        print('ERROR: Could not find', AWS_file)\n",
    "        return\n",
    "    AWS_file['Date'] = AWS_changedate(AWS_file['Date'])\n",
    "    return AWS_file\n",
    "    \n",
    "def AWS_changedate(date_list):\n",
    "    ### Changes the dates into a readable and manipulable format\n",
    "    \n",
    "    new_dates = []\n",
    "    for date in date_list:\n",
    "        try:\n",
    "            new_date = datetime.strptime(date, '%m/%d/%y %H:%M')\n",
    "        except:\n",
    "            new_date = -1\n",
    "        new_dates.append(new_date)\n",
    "    return new_dates\n",
    "\n",
    "def days_between(date1, date2):\n",
    "    ### Calculates the number of days between two dates\n",
    "    \n",
    "    \"\"\"Calculate the number of days in between two dates\"\"\"\n",
    "    delta=abs(date2-date1)\n",
    "    return(delta.days)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stake and AWS Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_dates(melt_dates, AWS_dates):\n",
    "    ### Determines the common date range for stake measurements and AWS measurements\n",
    "    \n",
    "    AWS_start_date = AWS_dates.iloc[0]\n",
    "    AWS_end_date = AWS_dates.iloc[-1]\n",
    "    AWS_2020_dates = AWS_dates.iloc[0:2209]\n",
    "    AWS_2020_end = AWS_2020_dates.iloc[-1]\n",
    "    model_dates = []\n",
    "    for m in (range(melt_dates.size-1)):\n",
    "        melt_start_date = melt_dates.iloc[m]\n",
    "        melt_end_date = melt_dates.iloc[m+1]\n",
    "        model_start_date = AWS_start_date\n",
    "        \n",
    "        model_end_date = AWS_end_date\n",
    "        if melt_start_date.year == melt_end_date.year and melt_start_date.year > 2019:\n",
    "            if not melt_start_date.year == 2020:\n",
    "                if melt_start_date > AWS_start_date:\n",
    "                    model_start_date = melt_start_date\n",
    "                if melt_end_date < AWS_end_date:\n",
    "                    model_end_date = melt_end_date\n",
    "            else:\n",
    "                model_end_date = AWS_2020_end\n",
    "                if melt_start_date > AWS_start_date:\n",
    "                    model_start_date = melt_start_date\n",
    "                if melt_end_date < AWS_2020_end:\n",
    "                    model_end_date = melt_end_date\n",
    "\n",
    "            model_range = (model_start_date, model_end_date)\n",
    "            model_dates.append(model_range)\n",
    "    return model_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPD and DDF methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_DDF(melt):\n",
    "    ### Determine the melt per day (mpd) and degree day factor (DDF) for each melt period\n",
    "    \n",
    "    AWS_file = build_AWS_dataset('AWS_infilled_2020-2021.csv')\n",
    "    T = AWS_file['T_RTD']\n",
    "    AWS_dates = AWS_file['Date']\n",
    "    melt_dates = melt['melt_dates']\n",
    "    model_dates = get_common_dates(melt_dates, AWS_dates)\n",
    "    mpd_list = []\n",
    "    DDF_list = []\n",
    "    debris_list = []\n",
    "    for date_range in model_dates:\n",
    "        num_days = days_between(date_range[0], date_range[1])\n",
    "        index=-1\n",
    "        for m in range(melt_dates.size - 1):\n",
    "            if melt_dates[m] == date_range[0]:\n",
    "                index = m+1\n",
    "                break\n",
    "        if not index == -1:\n",
    "            cur_mpd = melt.iloc[index][1] * 10 * 0.9 # (mm w.e./d)Convert to mm from cm\n",
    "            \n",
    "            total_melt = cur_mpd * num_days # (mm w.e.)\n",
    "            \n",
    "            cur_debris = melt['debris_depth'][index]\n",
    "            cur_ele = melt['elevation'][index]\n",
    "            i=1\n",
    "            while math.isnan(cur_ele):\n",
    "                cur_ele = melt['elevation'][index-i]\n",
    "                if i > index:\n",
    "                    break\n",
    "                i += 1\n",
    "\n",
    "            ele_factor = get_ele_factor(cur_ele, date_range[1].year)\n",
    "            \n",
    "            AWS_start = AWS_dates[AWS_dates == date_range[0]].index[0]\n",
    "            \n",
    "            AWS_end = AWS_dates[AWS_dates == date_range[1]].index[0]\n",
    "            \n",
    "            cur_PDD = (sum(T.iloc[AWS_start:AWS_end]) + len(T.iloc[AWS_start:AWS_end])*ele_factor) / 24 # ºC*d\n",
    "            \n",
    "            cur_DDF = total_melt / cur_PDD # mm w.e. / (ºC*d)\n",
    "            debris_list.append(cur_debris)\n",
    "            mpd_list.append(cur_mpd)\n",
    "            DDF_list.append(cur_DDF)\n",
    "            \n",
    "    DDF_df = pd.DataFrame(model_dates, columns = ['start_date', 'end_date'])\n",
    "\n",
    "    DDF_df['melt_per_day'] = mpd_list\n",
    "    DDF_df['DDF'] = DDF_list\n",
    "    DDF_df['debris_depth'] = debris_list\n",
    "    return DDF_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ele_factor(elevation, AWS_year):\n",
    "    ### Calculate the lapse rate for a stake's elevation\n",
    "    \n",
    "    if AWS_year < 2021:\n",
    "        AWS_ele = 585.5\n",
    "    else:\n",
    "        AWS_ele = 541\n",
    "        \n",
    "    ele_factor = -6.5*(elevation-AWS_ele)/1000\n",
    "    return ele_factor\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scatter_plots(DDF_dict):\n",
    "    gen = (stake_name for stake_name in DDF_dict.keys() if not DDF_dict[stake_name].empty)\n",
    "    debris_e20 = []\n",
    "    debris_l20 = []\n",
    "    debris_e21 = []\n",
    "    debris_l21 = []\n",
    "    mpds_e20 = []\n",
    "    mpds_l20 = []\n",
    "    mpds_e21 = []\n",
    "    mpds_l21 = []\n",
    "    DDFs_e20 = []\n",
    "    DDFs_l20 = []\n",
    "    DDFs_e21 = []\n",
    "    DDFs_l21 = []\n",
    "\n",
    "    for stake_name in gen:\n",
    "        cur_df = DDF_dict[stake_name]\n",
    "\n",
    "        for i in range(cur_df['melt_per_day'].size):\n",
    "            debris = cur_df['debris_depth']\n",
    "            mpds = cur_df['melt_per_day']\n",
    "            DDFs = cur_df['DDF']\n",
    "            \n",
    "            if not (math.isnan(debris[i]) or math.isnan(mpds[i]) or math.isnan(DDFs[i])):\n",
    "                cur_debris = debris[i]\n",
    "                cur_mpd = mpds[i]\n",
    "                cur_DDF = DDFs[i]\n",
    "                cur_start_date = cur_df['start_date'][i]\n",
    "                if cur_start_date.year == 2020:\n",
    "                    if cur_start_date.month < 7:\n",
    "                        debris_e20.append(cur_debris)\n",
    "                        mpds_e20.append(cur_mpd)\n",
    "                        DDFs_e20.append(cur_DDF)\n",
    "                    else:\n",
    "                        debris_l20.append(cur_debris)\n",
    "                        mpds_l20.append(cur_mpd)\n",
    "                        DDFs_l20.append(cur_DDF)\n",
    "                else:\n",
    "                    if cur_start_date.month < 7:\n",
    "                        debris_e21.append(cur_debris)\n",
    "                        mpds_e21.append(cur_mpd)\n",
    "                        DDFs_e21.append(cur_DDF)\n",
    "                    else:\n",
    "                        debris_l21.append(cur_debris)\n",
    "                        mpds_l21.append(cur_mpd)\n",
    "                        DDFs_l21.append(cur_DDF)\n",
    "            \n",
    "    \n",
    "    \n",
    "    del debris_e21[0]\n",
    "    del mpds_e21[0]\n",
    "    del DDFs_e21[0]\n",
    "    \n",
    "    x20 = debris_e20 + debris_l20\n",
    "    y20_mpd = mpds_e20 + mpds_l20\n",
    "    y20_DDF = DDFs_e20 + DDFs_l20\n",
    "    \n",
    "    x21 = debris_e21 + debris_l21\n",
    "    y21_mpd = mpds_e21 + mpds_l21\n",
    "    y21_DDF = DDFs_e21 + DDFs_l21\n",
    "    \n",
    "\n",
    "#     fig1 = plt.figure()\n",
    "#     ax1 = fig1.gca()\n",
    "    \n",
    "#     ax1.scatter(debris_e20, mpds_e20, facecolor='b', edgecolor=None, marker='o')\n",
    "#     ax1.scatter(debris_l20, mpds_l20, facecolor='r', edgecolor=None, marker='o')\n",
    "\n",
    "#     ax1.set_xlabel('Debris Depth (cm)')\n",
    "#     ax1.set_ylabel('Measured Melt Rate (mm w.e. d$^{-1}$)')\n",
    "    \n",
    "#     fig2 = plt.figure()\n",
    "#     ax2 = fig2.gca()\n",
    "    \n",
    "#     ax2.scatter(debris_e21, mpds_e21, facecolor='b', edgecolor=None, marker='o')\n",
    "#     ax2.scatter(debris_l21, mpds_l21, facecolor='r', edgecolor=None, marker='o')\n",
    "\n",
    "#     ax2.set_xlabel('Debris Depth (cm)')\n",
    "#     ax2.set_ylabel('Measured Melt Rate (mm w.e. d$^{-1}$)')\n",
    "\n",
    "    #MPD 20-21\n",
    "    fig3 = plt.figure()\n",
    "    ax3 = fig3.gca()\n",
    "    \n",
    "    ax3.scatter(debris_e20, mpds_e20, facecolor='r', edgecolor=None, marker='o', label = \"Early '20\")\n",
    "    ax3.scatter(debris_l20, mpds_l20, facecolor='r', edgecolor=None, marker='^', label = \"Late '20\")\n",
    "    ax3.scatter(debris_e21, mpds_e21, facecolor='orange', edgecolor=None, marker='o', label = \"Early '21\", zorder = -1)\n",
    "    ax3.scatter(debris_l21, mpds_l21, facecolor='orange', edgecolor=None, marker='^', label = \"Late '21\", zorder = -1)\n",
    "\n",
    "    ax3.set_xlabel('Debris Depth (cm)')\n",
    "    ax3.set_ylabel('Measured Melt Rate (mm w.e. d$^{-1})$')\n",
    "    \n",
    "    pars, cov = curve_fit(f=exp, xdata=x20 + x21, ydata=y20_mpd + y21_mpd, p0=[2.4, -.02], bounds=(-np.inf, np.inf))\n",
    "\n",
    "    curve_x_mpd = np.asarray(x20 + x21)\n",
    "    y_pred_mpd = exp(curve_x_mpd, *pars)\n",
    "\n",
    "    curve_x_mpd.sort()\n",
    "    curve_y_mpd = exp(curve_x_mpd, *pars)\n",
    "    \n",
    "    y_true_mpd = y20_mpd + y21_mpd\n",
    "    \n",
    "    r2_mpd = r2_score(y_true_mpd, y_pred_mpd)\n",
    "    \n",
    "    ax3.plot(curve_x_mpd, curve_y_mpd, linestyle='--', linewidth=1, color='k', label=\"'20-'21 (r$^2$=\" + str(np.round(r2_mpd,2)) + \")\", zorder = -1)\n",
    "    ax3.legend()\n",
    "    \n",
    "    fig3.savefig('../Exports/20_21_mpd', dpi=300)\n",
    "\n",
    "    #DDF 20-21\n",
    "    fig4 = plt.figure()\n",
    "    ax4 = fig4.gca()\n",
    "    \n",
    "    ax4.scatter(debris_e20, DDFs_e20, facecolor='r', edgecolor=None, marker='o', label = \"Early '20\")\n",
    "    ax4.scatter(debris_l20, DDFs_l20, facecolor='r', edgecolor=None, marker='^', label = \"Late '20\")\n",
    "    ax4.scatter(debris_e21, DDFs_e21, facecolor='orange', edgecolor=None, marker='o', label = \"Early '21\", zorder = -1)\n",
    "    ax4.scatter(debris_l21, DDFs_l21, facecolor='orange', edgecolor=None, marker='^', label = \"Late '21\", zorder = -1)\n",
    "    \n",
    "    ax4.set_xlabel('Debris Depth (cm)')\n",
    "    ax4.set_ylabel('Degree Day Factor (mm w.e. d$^{-1}$ $^oC^{-1}$)')\n",
    "    \n",
    "    pars2, cov2 = curve_fit(f=exp, xdata=x20 + x21, ydata=y20_DDF + y21_DDF, p0=[2.4, -.02], bounds=(-np.inf, np.inf))\n",
    "\n",
    "    curve_x_DDF = np.asarray(x20 + x21)\n",
    "    y_pred_DDF = exp(curve_x_DDF, *pars2)\n",
    "    \n",
    "    curve_x_DDF.sort()\n",
    "    curve_y_DDF = exp(curve_x_DDF, *pars2)\n",
    "    \n",
    "    y_true_DDF = y20_DDF + y21_DDF\n",
    "    \n",
    "    r2_DDF = r2_score(y_true_DDF, y_pred_DDF)\n",
    "    \n",
    "    ax4.plot(curve_x_DDF, curve_y_DDF, linestyle='--', linewidth=1, color='k', label=\"'20-'21 (r$^2$=\" + str(np.round(r2_DDF,2)) + \")\", zorder = -1)\n",
    "    ax4.legend()\n",
    "    \n",
    "    fig4.savefig('../Exports/20_21_DDF', dpi=300)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(x,a,b):\n",
    "    ### Defines an exponential function\n",
    "    \n",
    "    y = a*np.exp(x*b)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    stake_info = build_stake_dataset('Kennicott Stake Records-V4_NEW')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
